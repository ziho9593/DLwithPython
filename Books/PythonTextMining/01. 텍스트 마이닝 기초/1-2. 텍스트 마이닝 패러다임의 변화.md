## 1-2. 텍스트 마이닝 패러다임의 변화

딥러닝이 텍스트 마이닝의 트렌드를 확연히 바꾸었음은 분명하다. 지금은 텍스트 분류 등의 작업에 딥러닝 기반의 BERT를 쓰는 것이 일반화됐는데, BERT는 트렌스포머 기반 모형으로 자세한 작동원리를 이해하기 매우 어려운 편임에도 불구하고 최근 어지간한 작업에 모두 사용될 만큼 인기가 높다.

그렇다고 카운트 기반 방식 혹은 BOW가 한물 간 것은 아니다. 책 한권 정도 분량의 내용에 대해 문서를 분류해야 할 때는 여전히 카운트 기반의 문서 표현이 BERT 등 최신 모형보다 더 낫다는 연구결과가 있다. 따라서 여전히 BOW는 쓸모가 있으며, 간단한 작업에서 학습을 위해 적은 노력으로 비교적 좋은 성과를 올리기에 적합하다.

### 카운트 기반의 문서 표현
텍스트 마이닝에서 주어신 텍스트를 정형화된 데이터로 변환하려면 텍스트를 이해하는 것이 중요하다. 최근 사람의 이해방식을 최대한 반영하는 딥러닝 기법 이전에는 컴퓨터가 문장에 있는 단어들을 순사대로 읽어가며 이해할 수 있는 방법이 없었다. 그래서 생각한 최선의 방법은 '문장의 단어 개수를 세고, 주로 사용된 단어들을 이용해 그 문장의 내용을 파악하는 것'이었다.

카운트 기반의 문서 표현은 이러한 아이디어를 바탕으로 문서를 사용된 단어들의 빈도로 표현하는 것이다. 이 과정에서 단어들이 나타난 순서에 대한 정보는 사라진다. 즉, 문맥에 대한 정보는 사라지고 단어에 대한 통계만이 남게 된다.

그러나 텍스트 마이닝의 원래 목적인 텍스트 내용을 기반으로 어떤 사건을 예측하는 것은 이 정도의 정보만으로도 꽤나 훌륭한 결과를 보일 수 있다. 다시 말해, 텍스트의 내용을 완전히 이해하지 않더라도 단어 빈도들을 이용해 우리가 원하는 많은 작업들을 어느 정도 잘 수행 가능하다는 뜻이다.

텍스트 마이닝은 문서를 일정 길이의 벡터로 변환한다고 했는데, 카운트 기반 문서 표현은 각 단어별로 개수를 세어 이를 벡터로 만든다고 이해하면 쉽다. 예를 들어 사용된 단어가 A, B, C, D, E 5개고 각 단어별 개수가 3, 7, 4, 2, 5라면, 이것을 벡터로 만들어 [3, 7, 4, 2, 5]와 같은 리스트로 표현한다. 사용된 단어가 많다면 벡터의 크기 역시 커진다.

### 시퀀스 기반의 문서 표현
시퀀스 기반의 문서 표현은 카운트 기반 문서 표현의 문제점을 해결하고, 사람이 글을 읽고 이해하는 것과 유사한 방법으로 텍스트의 문맥을 이해하고자 하는 방식이다.

카운트 기반의 문서 표현이 단어들의 빈도를 이용한 하나의 벡터로 단번에 문서 전체를 표현한다면, 시퀀스 기반의 문서 표현은 각 단어를 먼저 벡터로 변환하고 이러한 벡터의 연속된 나열 혹은 시퀀스로 문서를 표현한다. 이러한 방식의 장점은 문맥을 이용함으로 더 정확하게 문장의 의미를 이해할 수 있다는 것이다. 연속된 단어의 형태로 문장을 이해하려면 RNN과 같은 딥러닝 기법을 필요로 한다.

단어를 벡터로 변환하는 가장 쉬운 방법은 단어를 일정 규칙에 따라 정렬하고 단어의 수만큼 벡터를 만든 후에 단어 자신의 위치만 1로 표현하는 것이다. 예를 들어 A, B, C, D, E가 있다면 A는 [1, 0, 0, 0, 0], B는 [0, 1, 0, 0, 0]과 같이 표현하는 것이다. 이와 같은 방식을 ***'원핫 인코딩'*** 이라고 한다.

그러나 보통 텍스트 마이닝은 하나의 문서보다는 수많은 문서의 집합을 다루기 때문에, 수많은 문서를 모두 같은 방식으로 임베딩할 수 있어야 한다. 그렇게 하려면 수많은 문서에 사용된 단어를 모두(목적에 따라 일부만 사용하는 것도 가능하긴 하지만) 포함해야 하는데, 그렇게 되면 단어를 벡터로 변환했을 때 벡터가 지나치게 커지는 문제가 있다.

예를 들어 문서의 집합에 사용된 단어가 10000개라면 각 단어를 크기가 10000인 벡터로 표현해야 한다. 이에 보통 딥러닝 기법에서는 특별한 과정을 거쳐 긴 벡터를 길이가 보통 200 정도인 짧은 벡터로 변환하는데, 이러한 과정을 ***'임베딩'*** 이라고 부르며 워드 임베딩과 문서 임베딩으로 구분할 수 있다.

또 다른 문제로 문서는 가변의 단어로 구성되므로 문서를 임베딩한 단어 벡터의 시퀀스로 표현했을 때 길이가 제각각이 된다는 점이다. 그러나 머신러닝이나 딥러닝은 보통 가변 길이의 입력을 허용하지 않아 일정한 길이로 맞추는 작업이 필요하다. 문서의 단어 수가 미리 정한 값보다 크면 단어를 잘라 길이를 맞추거나, 단어 수가 모자랄 때는 공백이나 미리 약속한 의미 없는 값으로 모자란 부분을 메꾼다. 이렇게 하면 '문서를 일정한 길이의 벡터로 변환'한다는 정의를 만족시킬 수 있다.