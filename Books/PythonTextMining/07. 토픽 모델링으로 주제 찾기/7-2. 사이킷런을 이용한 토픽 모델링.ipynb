{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2. 사이킷런을 이용한 토픽 모델링\n",
    "\n",
    "### 데이터 준비\n",
    "20 뉴스그룹 데이터를 사용해 토픽 모델링을 실습하고자 한다. 익숙한 데이터이므로 결과를 해석하기에도 용이하다. 문서분류와는 달리 예측을 할 필요가 없으므로 학습 데이터만 사용한다. 문서 분류에서는 네 개의 카테고리만 선택했으나, 여기서는 좀 더 다양한 토픽들을 살펴보기 위해 여섯 개로 카테고리를 늘린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train set size: 3219\n",
      "# Selected categories: ['alt.atheism', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'sci.crypt', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space', 'comp.sys.ibm.pc.hardware', 'sci.crypt']\n",
    "\n",
    "# 학습 데이터셋을 가져옴\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "\n",
    "print('# Train set size:', len(newsgroups_train.data))\n",
    "print('# Selected categories:', newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 준비되면 카운트 벡터를 생성한다. 사이킷런의 LDA 라이브러리는 카운트 벡터를 입력으로 사용한다. 문서분류에서는 단어 수를 제한하지 않는 편이 가장 좋은 성능을 보였으나, 수행 시간을 고려해 초기에 사용했던 인수들을 그대로 사용한다. 즉 특성 수를 2,000개로 제한하고 min_df와 max_df를 각각 5와 0.5로 해서 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(token_pattern=\"[\\w']{3,}\", stop_words='english', max_features=2000, min_df=5, max_df=0.5)\n",
    "review_cv = cv.fit_transform(newsgroups_train.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA 토픽 모델링 실행\n",
    "사이킷런에서 LDA를 지원하는 클래스는 [LatentDirichletAllocation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)이다. 앞선 설명에서 하이퍼 파라미터로 말했던 토픽의 수, α, β 외에 max_iter, learning_method, n_jobs, random_stete 매개변수가 있다. 먼저 n_components는 토픽의 수를 지정한다. 우선은 10으로 시작하지만 가장 중요한 하이퍼 파라미터이므로 최적값을 찾는 방법을 이후에 알아본다.\n",
    "\n",
    "매개변수 max_iter는 알고리즘의 최대 반복 횟수다. 보통 최종 모형에서는 충분히 큰 값을 준다고 하지만, 그 이전에 수렴하는 경우도 많으므로 적절하게 선택하면 된다. 기본값은 10이다. 실습이므로 시간이 많이 걸린다면 더 줄여도 되지만 5 이하가 되면 제대로 결과가 안 나올 수 있다.\n",
    "\n",
    "topic_word_prior는 β를 말하며, 앞선 설명과 같이 토픽의 사전 단어분포를 결정하는 매개변수다. 기본값은 1/n_components다. doc_topic_prior는 α를 의미하며 문서의 사전 토픽분포를 결정한다. 기본값은 마찬가지로 일반적으로 n_components다. 이 두 값을 얼마로 설정하는 것이 좋은지에 대해 정해진 답은 없다. 다만 토픽 모델링으로 유명한 논문에서 β는 0.1, α는 50/n_components 값을 사용했으므로 이 근처에서 직접 적절한 값을 찾아보는 것을 추첞나다. 다만 논문에서는 토픽의 수를 10에서 1,000개까지 테스트하는 동안 값을 변경햇으므로 실습에서는 1.0 정도로 해본다.\n",
    "\n",
    "learning_method는 batch와 online의 두 값이 있으며, batch가 online에 비해 더 성능이 좋은 대신 느리다. n_jobs는 실행 시 사용하는 프로세서의 수로 값을 주지 않으면 한 개, -1이면 가능한 모든 프로세서를 사용한다. random_state는 지금까지와 마찬가지로 랜덤 시드를 지정해 재실행 및 확인이 가능하도록 해준다.\n",
    "\n",
    "아래와 같이 기본적인 인수를 주고 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shape of review_topics: (3219, 10)\n",
      "# Sample of review_topics: [0.015 0.007 0.008 0.829 0.008 0.008 0.02  0.007 0.007 0.091]\n",
      "# Sum of topic weights of documents: [0.082 0.082 0.094 0.109 0.114 0.138 0.086 0.071 0.072 0.152]\n",
      "# shape of topic word distribution: (10, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, # 추출할 topic의 수\n",
    "                                max_iter=5, \n",
    "                                topic_word_prior=0.1, doc_topic_prior=1.0,\n",
    "                                learning_method='online', \n",
    "                                n_jobs=-1, # 사용 processor 수\n",
    "                                random_state=0)\n",
    "\n",
    "review_topics = lda.fit_transform(review_cv)\n",
    "print('# shape of review_topics:', review_topics.shape)\n",
    "print('# Sample of review_topics:', review_topics[0])\n",
    "\n",
    "gross_topic_weights = np.mean(review_topics, axis=0)\n",
    "print('# Sum of topic weights of documents:', gross_topic_weights)\n",
    "\n",
    "print('# shape of topic word distribution:', lda.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 보면 LDA를 이용해 학습하고 변환한 결과가 저장된 review_topics의 shape이 (3219, 10)인 것을 볼 수 있는데, 여기서 행은 각 문서 그대로이고 열의 값들은 LDA가 추출한 토픽의 비중을 나타낸다. 즉 LDA 변환결과는 각 문서별로 토픽분포를 보여주며, 이는 위 LDA의 원리 설명에서 θ에 해당한다.\n",
    "\n",
    "위 결과와 같이 review_topics의 첫째 행을 출력하면 첫 문서의 각 토픽에 대한 분포를 볼 수 있으며, 넷째 토픽의 비중이 압도적으로 크고 나머지는 비슷한 것을 알 수 있다. numpy로 열에 대해 총합을 구하면 문서 전체에 나타난 토픽의 평균 분포를 알 수 있다. 즉 말뭉치 전체에서는 10번째 토픽이 15.2%로 가장 많이 나타났으며, 다음이 13.8%인 6번째 토픽이다.\n",
    "\n",
    "그러나 위 결과만 가지고는 각 토픽의 내용을 알 수 없다. 토픽의 단어 분포를 보면 토픽의 내용을 짐작할 수 있는데, 이는 LDA 모형에서 φ에 해당하고, 사이킷런의 LDA 클래스에서는 components_ 속성이 이 값을 가지고 있다. 위 예와 같이 lda_components_의 shape을 출력해보면 (10, 2000)이 나오는데, 이는 각 토픽에 대해 카운트 벡터에서 사용한 단어 2,000개의 비중을 표현하기 때문이다.\n",
    "\n",
    "토픽의 내용을 파악하려고 모든 단어의 비중을 들여다보는 것은 사실상 불가능하므로, 보통은 가장 비중이 높은 단어 10~20개 정도를 본다. 토픽별로 비중이 높은 상위 단어들을 찾아 순서대로 출력하기 위해 아래와 같이 print_top_words 함수를 정의하고, 위 결과에 적용해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: com, article, sandvik, apple, university, kent, science, wrote, islam, frank\n",
      "Topic #1: image, graphics, file, files, ftp, software, available, program, data, use\n",
      "Topic #2: com, access, posting, net, digex, article, ibm, internet, like, pat\n",
      "Topic #3: article, com, don't, keith, nntp, think, host, just, posting, sgi\n",
      "Topic #4: key, clipper, chip, encryption, government, com, keys, law, escrow, use\n",
      "Topic #5: scsi, university, nntp, host, thanks, posting, com, know, bit, bus\n",
      "Topic #6: space, nasa, gov, launch, orbit, center, earth, shuttle, satellite, research\n",
      "Topic #7: drive, disk, hard, com, controller, drives, dos, problem, tape, floppy\n",
      "Topic #8: key, public, mail, faq, message, pgp, information, university, group, des\n",
      "Topic #9: god, people, don't, jesus, just, think, say, believe, does, know\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d: \" % topic_idx, end='')\n",
    "        print(\", \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        # print(\", \".join([feature_names[i]+'('+str(topic[i])+')' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        # 위 slicing에서 맨 뒤 -1은 역순을 의미, 역순으로 했을 때 처음부터 n_top_words까지\n",
    "    print()\n",
    "\n",
    "print_top_words(lda, cv.get_feature_names_out(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 보고 토픽이 제대로 분류됐는지 확인하는 것은 분석가의 몫이다. 1번 토픽의 경우 image, graphics, file, software 등의 단어를 통해 말뭉치를 이루는 카테고리들 중 graphics에 해당하는 토픽임을 짐작할 수 있다. 마찬가지로 2번 토픽은 space, nasam access, launch, earth 등을 통해 space에 대한 토픽임을 알 수 있다.\n",
    "\n",
    "토픽 모델링을 수행한 결과에 대한 논문이나 신문기사를 보면 토픽에 제목이 있다. 이 제목은 통상적으로 분석가가 판단해서 만든다. 상위 비중을 차지하는 단어들을 보고 짐작해 이름을 짓는데, 이 과정에서 분석가의 해석이 많이 반영된다. 빈도가 높은 단어들로부터 토픽의 이름을 자동으로 생성하는 시도가 있으나, 아직 높은 정확성을 기대하기는 어렵다.\n",
    "\n",
    "위에서 적절한 토픽의 수를 결정하기 위해 모형의 성능을 측정하는 것에 대해 언급했는데, 혼란도나 토픽 응집도와 같은 수치에 전적으로 의존하기보다 사람의 판단이 중요하다고 이야기한 것이 바로 이와 같은 맥락이다. 성능상으로 좋은 수치를 보인다 해도 토픽을 해석하기가 어렵다면 좋은 결과라고 하기 어렵다.\n",
    "\n",
    "### 최적의 토픽 수 선택하기\n",
    "토픽 모델링에서 가장 중요한 하이퍼 파라미터는 바로 토픽의 수다. 토픽 수를 결정하기 위해 다양한 토픽 수를 적용한 모형들에 대해 혼란도와 토픽 응집도를 계산하는데, 사이킷런은 혼란도만 공식적으로 제공한다. 토픽 응집도를 알고 싶다면 아직까지는 직접 계산해야 한다. 여기서는 perplexity를 계산하고 그래프를 통해 적절한 값을 선택하는 과정을 실습해보고자 한다. \n",
    "\n",
    "토픽의 수를 변화시키면서 LDA를 수행하고 preplexity를 계산한 후 그래프로 그려주는 show_perplexity 함수를 아래와 같이 구현했다. 이때 주의할 점은, 시간을 줄이기 위해 max_iter를 너무 낮추면 제대로 수렴이 되지 않아 perplexity값이 높게 나오고 토픽 수에 비례하는 경향이 있다. 따라서 최소 5 이상의 값을 주는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components: 6, perplexity: 1052.061\n",
      "n_components: 7, perplexity: 1055.910\n",
      "n_components: 8, perplexity: 1027.856\n",
      "n_components: 9, perplexity: 1018.301\n",
      "n_components: 10, perplexity: 1024.421\n",
      "n_components: 11, perplexity: 1035.376\n",
      "n_components: 12, perplexity: 1031.050\n",
      "n_components: 13, perplexity: 1039.640\n",
      "n_components: 14, perplexity: 1038.313\n",
      "n_components: 15, perplexity: 1043.554\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components with minimum perplexity: 9\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_perplexity(cv, start=10, end=30, max_iter=5, topic_word_prior=0.1, doc_topic_prior=1.0):\n",
    "    iter_num = []\n",
    "    per_value = []\n",
    "\n",
    "    for i in range(start, end + 1):\n",
    "        lda = LatentDirichletAllocation(n_components=i, max_iter=max_iter, topic_word_prior=topic_word_prior, \n",
    "                                        doc_topic_prior=doc_topic_prior, learning_method='batch', n_jobs=-1,\n",
    "                                        random_state=7)    \n",
    "        lda.fit(cv)\n",
    "        iter_num.append(i)\n",
    "        pv = lda.perplexity(cv)\n",
    "        per_value.append(pv)\n",
    "        print(f'n_components: {i}, perplexity: {pv:0.3f}')\n",
    "\n",
    "    plt.plot(iter_num, per_value, 'g-')\n",
    "    plt.show()\n",
    "    return start + per_value.index(min(per_value))\n",
    "\n",
    "print(\"n_components with minimum perplexity:\", show_perplexity(review_cv, start=6, end=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 보면 토픽의 수가 8일 때 주변의 다른 값에 비해 perplexity가 낮은 것을 볼 수 있다. 물론 몇 개의 대안을 놓고 각각 실행해서 해석이 더 잘되는 모형을 선택하는 것이 바람직하지만, 여기서는 토픽의 수를 8로 놓고 본격적인 LDA를 실행해서 결과를 살펴보기로 한다. max_iter는 5에서 20으로 늘렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: graphics, image, mail, available, file, ftp, information, files, data, software\n",
      "Topic #1: space, nasa, gov, orbit, earth, ___, center, launch, research, washington\n",
      "Topic #2: com, keith, nntp, host, posting, morality, article, caltech, sgi, objective\n",
      "Topic #3: com, article, jesus, know, god, just, posting, john, host, nntp\n",
      "Topic #4: people, god, don't, does, think, say, believe, just, like, way\n",
      "Topic #5: drive, scsi, com, card, disk, thanks, ide, controller, bus, hard\n",
      "Topic #6: article, com, just, access, like, posting, nntp, host, space, net\n",
      "Topic #7: key, encryption, clipper, chip, com, government, keys, use, security, public\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8, # 추출할 topic의 수를 지정\n",
    "                                max_iter=20, \n",
    "                                topic_word_prior=0.1, \n",
    "                                doc_topic_prior=1.0,\n",
    "                                learning_method='batch',\n",
    "                                n_jobs=-1, \n",
    "                                random_state=7)\n",
    "\n",
    "review_topics = lda.fit_transform(review_cv)\n",
    "\n",
    "print_top_words(lda, cv.get_feature_names_out(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음 선택했던 카테고리가 ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space', 'comp.sys.ibm.pc.hardware', 'sci.crypt'] 였음을 기억해보면, Topic 0: 'comp.graphics', Topic 3: 'talk.religion.misc', Topic 5: 'comp.sys.ibm.pc.hardware', Topic 6: 'sci.space', Topic 7: 'sci.crypt'는 비교적 명확해 보인다. Topic 1과 Topic 2는 살짝 모호해 보이며 (물론 지식이 많다면 해석을 더 잘할 수도 있다), Topic 4는 'alt.atheism'과 'talk.religion.misc'이 섞여 있는 것처럼 보인다.\n",
    "\n",
    "만일 카테고리에 대한 사전정보가 전혀 없었다면 위 결과가 나름 말뭉치에 내재된 주제들을 잘 분류했다고 볼 수 있을 것이다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "622aab9bd826807b98c9306e1877170a0c8f932fd0d9d680a7a0b4f2ccac43fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
