{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02. OpenCV-Python 기초 사용법"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 영상의 속성과 픽셀 값 참조\n",
    "\n",
    "### OpenCV 영상 데이터 자료형과 NumPy 자료형\n",
    "- OpenCV는 영상 데이터를 **numpy.ndarray**로 표현\n",
    "    - ndim: 차원 수. len(img.shape)과 같음.\n",
    "    - shape: 각 차원의 크기. (h, w) 또는 (h, w, 3)\n",
    "    - size: 전체 원소 개수\n",
    "    - dtype: 원소의 데이터 타입. 영상 데이터는 **uint8**.\n",
    "- OpenCV 영상 데이터 자료형과 NumPy 자료형\n",
    "    |OpenCV 자료형 (1채널)|Numpy자료형|구분|\n",
    "    |-----|-----|-----|\n",
    "    |cv2.CV_8U|numpy.uint8|8비트 부호없는 정수|\n",
    "    |cv2.CV_8S|numpy.int8|8비트 부호있는 정수|\n",
    "    |cv2.CV_16U|numpy.uint16|16비트 부호없는 정수|\n",
    "    |cv2.CV_16S|numpy.int16|16비트 부호있는 정수|\n",
    "    |cv2.CV_32S|numpy.int32|32비트 부호있는 정수|\n",
    "    |cv2.CV_16F|numpy.float16|16비트 부동소수형|\n",
    "    |cv2.CV_32F|numpy.float32|32비트 부동소수형|\n",
    "    |cv2.CV_64F|numpy.float64|64비트 부동소수형|\n",
    "    - 그레이스케일 영상: cv2.CV_8UC1 → numpy.uint8, shape = (h, w)\n",
    "    - 컬러 영상: cv2.CV_8UC3 → numpy.uint8, shape = (h, w, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영상의 속성 참조 예제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('./data/images/cat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('./data/images/cat.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "print('type(img1):', type(img1)) \n",
    "print('img1.shape:', img1.shape) \n",
    "print('img2.shape:', img2.shape) \n",
    "print('img2.dtype:', img2.dtype) \n",
    "\n",
    "h, w = img2.shape[:2]\n",
    "print(f'img2 size: {w} x {h}')\n",
    "\n",
    "if len(img1.shape) == 2:\n",
    "    print('img1 is a grayscale image')\n",
    "elif len(img1.shape) == 3:\n",
    "    print('img1 is a truecolor image')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영상의 픽셀 값 참조 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./data/images/cat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('./data/images/cat.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "img1[:,:] = 255\n",
    "img2[:,:] = (0, 0, 255)\n",
    "\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 영상의 생성, 복사, 부분 영상 추출\n",
    "\n",
    "### 지정한 크기로 새 영상 생성하기\n",
    "```py\n",
    "numpy.empty(shape, dtype=float, ...) -> arr\n",
    "numpy.zeros(shape, dtype=float, ...) -> arr\n",
    "numpy.ones(shape, dtype=None, ...) -> arr\n",
    "numpy.full(shape, fill_value, dtype=None, ...) -> arr\n",
    "```\n",
    "- shape: 각 차원의 크기. (h, w) 또는 (h, w, 3)\n",
    "- dtype: 원소의 데이터 타입. 일반적인 영상이면 numpy.uint8 지정\n",
    "- arr: 생성된 영상(numpy.ndarray)\n",
    "- 참고 사항\n",
    "    - numpy.empty() 함수는 임의의 값으로 초기화된 배열을 생성\n",
    "    - numpy.zeros() 함수는 0으로 초기화된 배열을 생성\n",
    "    - numpy.ones() 함수는 1로 초기화된 배열을 생성\n",
    "    - numpy.full() 함수는 fill_value로 초기화된 배열을 생성\n",
    "\n",
    "### 영상의 생성 예제 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img1 = np.empty((480, 640), dtype=np.uint8)                   # grayscale image\n",
    "img2 = np.zeros((480, 640, 3), dtype=np.uint8)                # color image\n",
    "img3 = np.ones((480, 640), dtype=np.uint8) * 255              # white\n",
    "img4 = np.full((480, 640, 3), 128, dtype=np.uint8)            # gray\n",
    "img5 = np.full((480, 640, 3), (0, 255, 255), dtype=np.uint8)  # yellow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영상의 참조 및 복사 예제 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./data/images/HappyFish.jpg')\n",
    "\n",
    "img2 = img1\n",
    "img3 = img1.copy()\n",
    "\n",
    "cv2.imshow('img1', img1)  # HappyFish\n",
    "cv2.imshow('img2', img2)  # HappyFish\n",
    "cv2.imshow('img3', img3)  # HappyFish\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1[:, :] = (0, 255, 255)\n",
    "\n",
    "cv2.imshow('img1', img1)  # yellow\n",
    "cv2.imshow('img2', img2)  # yellow\n",
    "cv2.imshow('img3', img3)  # HappyFish\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부분 영상 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./data/images/HappyFish.jpg')\n",
    "\n",
    "img2 = img1[40:120, 30:150] # numpy.ndarray의 슬라이싱\n",
    "img3 = img1[40:120, 30:150].copy()\n",
    "\n",
    "img2.fill(0)\n",
    "\n",
    "cv2.imshow('img1', img1)  # 얼굴 부분이 잘린 HappyFish\n",
    "cv2.imshow('img2', img2)  # black\n",
    "cv2.imshow('img3', img3)  # HappyFish의 원래 얼굴\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./data/images/HappyFish.jpg')\n",
    "\n",
    "img2 = img1[40:120, 30:150] # numpy.ndarray의 슬라이싱\n",
    "img3 = img1[40:120, 30:150].copy()\n",
    "\n",
    "cv2.circle(img2, (50, 50), 20, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('img1', img1)  # 얼굴에 빨간 동그라미가 생긴 HappyFish\n",
    "cv2.imshow('img2', img2)  # 빨간 동그라미가 생긴 HappyFish의 얼굴 부분\n",
    "cv2.imshow('img3', img3)  # HappyFish의 원래 얼굴\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 마스크 연산과 ROI\n",
    "\n",
    "### ROI\n",
    "- Region of Interest, 관심 영역\n",
    "- 영상에서 특정 연산을 수행하고자 하는 임의의 부분 영역\n",
    "\n",
    "### 마스크 연산\n",
    "- OpenCV는 일부 함수에 대해 ROI 연산을 지원하며, 이때 **마스크 영상**을 인자로 함께 전달해야 함  \n",
    "  e.g.) cv2.copyTo(), cv2.calcHist(), cv2.bitwise_or(), cv2.matchTemplate(), etc.\n",
    "- 마스크 영상은 cv2.CV_8UC1 타입(그레이스케일 영상)\n",
    "- 마스크 영상의 픽셀 값이 0이 아닌 위치에서만 연산이 수행됨  \n",
    "  → 보통 마스크 영상으로는 0 또는 255로 구성된 이진 영상(binary image)을 사용\n",
    "\n",
    "### 마스크 연산을 지원하는 픽셀 값 복사 함수\n",
    "```py \n",
    "cv2.copyTo(src, mask, dst=None) -> dst\n",
    "```\n",
    "- src: 입력 영상\n",
    "- mask: 마스크 영상. cv2.CV_8U. (numpy.uint8), 0이 아닌 픽셀에 대해서만 복사 연산을 수행\n",
    "- dst: 출력 영상. 만약 src와 크기 및 타입이 같은 dst를 입력으로 지정하면 dst를 새로 생성하지 않고 연산을 수행. 그렇지않으면 dst를 새로 생성하여 연산을 수행한 후 반환함.\n",
    "\n",
    "### 마스크 연산 예제\n",
    "- src, mask, dst는 모두 크기가 같아야 함.\n",
    "- src와 dst는 같은 타입이어야 하고, mask는 그레이스케일 타입의 이진 영상.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/images/airplane.bmp', cv2.IMREAD_COLOR)\n",
    "mask = cv2.imread('./data/images/mask_plane.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "dst = cv2.imread('./data/images/field.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.copyTo(src, mask, dst)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy의 불리언 인덱싱(Boolean indexing)을 이용한 마스크 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/images/airplane.bmp', cv2.IMREAD_COLOR)\n",
    "mask = cv2.imread('./data/images/mask_plane.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "dst = cv2.imread('./data/images/field.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "dst[mask > 0] = src[mask > 0]\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배경이 투명한 로고 파일에 대한 마스크 연산\n",
    "- cv2.IMREAD_UNCHANGED: 마스크 영상을 4번째 채널로 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/images/opencv-logo-white.png', cv2.IMREAD_UNCHANGED)\n",
    "mask = src[:, :, -1]\n",
    "src = src[:, :, :3]\n",
    "dst = cv2.imread('./data/images/field.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "crop = dst[100:h+100, 100:w+100]\n",
    "\n",
    "cv2.copyTo(src, mask, crop)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. OpenCV 그리기 함수\n",
    "\n",
    "### OpenCV 그리기 함수\n",
    "- OpenCV는 영상에 선, 도형, 문자열을 출력하는 그리기 함수를 제공\n",
    "- 선 그리기: 직선, 화살표, 마커 등\n",
    "- 도형 그리기: 사각형, 원, 타원, 다각형 등\n",
    "- 문자열 출력\n",
    "\n",
    "### 그리기 함수 사용 시 주의할 점\n",
    "- 그리기 알고리즘을 이용하여 영상의 픽셀 값 자체를 변경  \n",
    "  → 원본 영상이 필요하면 복사본을 만들어서 그리기 & 출력\n",
    "- 그레이스케일 영상에는 컬러로 그리기 안 됨  \n",
    "  → cv2.cvtColor() 함수로 BGR 컬러 영상으로 변환한 후 그리기 함수 호출\n",
    "\n",
    "### 직선 그리기\n",
    "```py\n",
    "cv2.line(img, pt1, pt2, color, thickness=None, lineType=None, shift=None) -> img\n",
    "```\n",
    "- img: 그림을 그릴 영상\n",
    "- pt1, pt2: 직선의 시작점과 끝점. (x, y) 튜플\n",
    "- color: 선 색상 또는 밝기. (B, G, R) 튜플 또는 정수값\n",
    "- thickness: 선 두께. 기본값은 1\n",
    "- lineType: 선 타입. cv2.LINE_4, cv2.LINE_8, cv2.LINE_AA 중 선택. 기본값은 cv2.LINE_8\n",
    "- shift: 그리기 좌표 값의 축소 비율. 기본값은 0\n",
    "\n",
    "### 사각형 그리기\n",
    "```py\n",
    "cv2.rectangle(img, pt1, pt2, color, thickness=None, lineType=None, shift=None) -> img\n",
    "cv2.rectangle(img, rec, color, thickness=None, lineType=None, shift=None) -> img\n",
    "```\n",
    "- img: 그림을 그릴 영상\n",
    "- pt1, pt2: 사각형의 두 꼭지점 좌표. (x, y) 튜플\n",
    "- rec: 사각형 위치 정보. (x, y, w, h) 튜플\n",
    "- color: 선 색상 또는 밝기. (B, G, R) 튜플 또는 정수값\n",
    "- thickness: 선 두께. 기본값은 1. 음수(-1)를 지정하면 내부를 채움\n",
    "- lineType: 선 타입. cv2.LINE_4, cv2.LINE_8, cv2.LINE_AA 중 선택. 기본값은 cv2.LINE_8\n",
    "- shift: 그리기 좌표 값의 축소 비율. 기본값은 0\n",
    "\n",
    "### 원 그리기\n",
    "```py\n",
    "cv2.circle(img, center, radius, color, thickness=None, lineType=None, shift=None) -> img\n",
    "```\n",
    "- img: 그림을 그릴 영상\n",
    "- pts: 다각형 외곽 점들의 좌표 배열. numpy.ndarray의 리스트. e.g.) [np.array([[10, 10], [50, 50], [10, 50]], dtype=np.int32)]\n",
    "- isClosed: 폐곡선 여부. True 또는 False 지정\n",
    "- color: 선 색상 또는 밝기. (B, G, R) 튜플 또는 정수값\n",
    "- thickness: 선 두께. 기본값은 1. 음수(-1)를 지정하면 내부를 채움.\n",
    "- lineType: 선 타입. cv2.LINE_4, cv2.LINE_8, cv2.LINE_AA 중 선택. 기본값은 cv2.LINE_8\n",
    "- shift: 그리기 좌표 값의 축소 비율. 기본값은 0.\n",
    "\n",
    "### 문자열 출력\n",
    "```py\n",
    "cv2.putText(img, text, org, fontFace, fontScale, color, thickness=None, lineType=None, bottomLeftOrigin=None) -> img\n",
    "```\n",
    "- img: 그림을 그릴 영상\n",
    "- text: 출력할 문자열\n",
    "- org: 영상에서 문자열을 출력할 위치의 좌측 하단 좌표. (x, y) 튜플\n",
    "- fontFace: 폰트 종류. cv2.FONT_HERSHEY_ 로 시작하는 상수 중 선택\n",
    "- fontScale: 폰트 크기 확대/축소 비율\n",
    "- color: 선 색상 또는 밝기. (B, G, R) 튜플 또는 정수값\n",
    "- thickness: 선 두께. 기본값은 1. 음수(-1)를 지정하면 내부를 채움\n",
    "- lineType: 선 타입. cv2.LINE_4, cv2.LINE_8, cv2.LINE_AA 중 선택\n",
    "- bottomLeftOrigin: True이면 영상의 좌측 하단을 원점으로 간주. 기본값은 False.\n",
    "\n",
    "### 다양한 그리기 함수 실행 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.full((400, 400, 3), 255, np.uint8)\n",
    "\n",
    "cv2.line(img, (50, 50), (200, 50), (0, 0, 255), 5)\n",
    "cv2.line(img, (50, 60), (150, 160), (0, 0, 128))\n",
    "\n",
    "cv2.rectangle(img, (50, 200, 150, 100), (0, 255, 0), 2)\n",
    "cv2.rectangle(img, (70, 220), (180, 280), (0, 128, 0), -1)\n",
    "\n",
    "cv2.circle(img, (300, 100), 60, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "cv2.circle(img, (300, 100), 30, (255, 255, 0), -1, cv2.LINE_AA)\n",
    "\n",
    "pts = np.array([[250, 200], [300, 200], [350, 300], [250, 300]])\n",
    "cv2.polylines(img, [pts], True, (255, 0, 255), 2)\n",
    "\n",
    "text = 'Hello? OpenCV ' + cv2.__version__\n",
    "cv2.putText(img, text, (50, 350), cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 카메라와 동영상 처리하기\n",
    "\n",
    "### 05-1. cv2.VideoCapture 클래스\n",
    "- OpenCV에서는 카메라와 동영상으로부터 프레임(frame)을 받아오는 작업을 cv2.VideoCapture 클래스 하나로 처리함\n",
    "\n",
    "#### 카메라 열기\n",
    "```py\n",
    "cv2.VideoCapture(index, apiPreference=None) -> retval\n",
    "```\n",
    "- index: camera_id + domain_offset_id\n",
    "- apiPreference: 선호하는 카메라 처리 방법을 지정\n",
    "- retval: cv2.VideoCapture 객체\n",
    "\n",
    "```py\n",
    "cv2.VideoCapture.open(index, apiPreference=None) -> retval\n",
    "```\n",
    "- retval: 성공하면 True, 실패하면 False.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비디오 캡쳐가 준비되었는지 확인\n",
    "```py\n",
    "cv2.VideoCapture.isOpened() -> retval\n",
    "```\n",
    "- retval: 성공하면 True, 실패하면 False.\n",
    "\n",
    "#### 프레임 받아오기\n",
    "```py\n",
    "cv2.VideoCapture.read(image=None) -> retval, image\n",
    "```\n",
    "- retval: 성공하면 True, 실패하면 False.\n",
    "- image: 현재 프레임 (numpy.ndarray)\n",
    "\n",
    "#### 카메라, 비디오 장치 속성 값 참조\n",
    "```py\n",
    "cv2.VideoCapture.get(propId) -> retval\n",
    "```\n",
    "- propId: 속성 상수. ([OpenCV 문서](https://docs.opencv.org/4.1.0/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d) 참조)\n",
    "    - CAP_PROP_FRAME_WIDTH: 프레임 가로 크기\n",
    "    - CAP_PROP_FRAME_HEIGHT: 프레임 세로 크기\n",
    "    - CAP_PROP_FPS: 초당 프레임 수\n",
    "    - CAP_PROP_FRAME_COUNT: 비디오 파일의 총 프레임 수\n",
    "    - CAP_PROP_POS_MSEC: 밀리초 단위로 현재 위치\n",
    "    - CAP_PROP_POS_FRAMES: 현재 프레임 번호\n",
    "    - CAP_PROP_EXPOSURE: 노출\n",
    "- retval: 성공하면 해당 속성 값, 실패하면 0.\n",
    "\n",
    "```py\n",
    "cv2.VideoCapture.set(propId, value) -> retval\n",
    "```\n",
    "- propId: 속성 상수\n",
    "- value: 속성 값\n",
    "- retval: 성공하면 True, 실패하면 False.\n",
    "\n",
    "#### 카메라 처리 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "\n",
    "# 기본 카메라 장치 열기\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(f'{int(w)} x {int(h)}')\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(f'{int(w)} x {int(h)}')\n",
    "\n",
    "\n",
    "while 1:\n",
    "    # 카메라로부터 프레임을 정상적으로 받아오면 \n",
    "    # ret에는 True, frame에는 해당 프레임이 저장됨.\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # inversed = ~frame              # 현재 프레임 반전\n",
    "    edge = cv2.Canny(frame, 50, 150) # 윤곽선만 나타나도록\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('edge', edge)\n",
    "    \n",
    "    if cv2.waitKey(20) == 27:   # 20ms을 기다린 후 다음 프레임 처리,\n",
    "        break                   # ESC키를 누르면 while 루프 종료.\n",
    "\n",
    "cap.release()                   # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 동영상 처리 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./data/videos/video1.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(20) == 27: \n",
    "        break     \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-2. cv2.VideoWriter 클래스\n",
    "- OpenCV에서는 cv2.VideoWriter 클래스를 이용하여 일련의 프레임을 동영상 파일로\n",
    "저장할 수 있음\n",
    "- 일련의 프레임은 모두 크기와 데이터 타입이 같아야 함\n",
    "\n",
    "#### Fourcc (4-문자 코드, four character code)\n",
    "- 동영상 파일의 코덱, 압축 방식, 색상, 픽셀 포맷 등을 정의하는 정수 값\n",
    "    - cv2.VideoWriter_fourcc(*'DIVX'): DIVX MPEG-4 코덱\n",
    "    - cv2.VideoWriter_fourcc(*'XVID'): XVID MPEG-4 코덱\n",
    "    - cv2.VideoWriter_fourcc(*'FMP4'): FFMPEG MPEG-4 코덱\n",
    "    - cv2.VideoWriter_fourcc(*'X264'): H.264/AVC 코덱\n",
    "    - cv2.VideoWriter_fourcc(*'MJPG'): Motion-JPEG 코덱\n",
    "\n",
    "#### 저장을 위한 동영상 파일 열기\n",
    "```py\n",
    "cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor=None) -> retval\n",
    "```\n",
    "- filename: 비디오 파일 이름 (e.g. 'video.mp4')\n",
    "- fourcc: fourcc (e.g. cv2.VideoWriter_fourcc(*'DIVX'))\n",
    "- fps: 초당 프레임 수 (e.g. 30)\n",
    "- frameSize: 프레임 크기. (width, height) 형태의 튜플.\n",
    "- isColor: 컬러 영상이면 True, 그렇지않으면 False.\n",
    "- retval: cv2.VideoWriter 객체\n",
    "\n",
    "```py\n",
    "cv2.VideoWriter.open(filename, fourcc, fps, frameSize, isColor=None) -> retval\n",
    "```\n",
    "- retval: 성공하면 True, 실패하면 False.\n",
    "\n",
    "#### 비디오 파일이 준비되었는지 확인\n",
    "```py \n",
    "cv2.VideoWriter.isOpened() -> retval\n",
    "```\n",
    "- retval: 성공하면 True, 실패하면 False.\n",
    "\n",
    "```py\n",
    "cv2.VideoWriter.write(image) -> None\n",
    "```\n",
    "- image: 저장할 프레임 (numpy.ndarray)\n",
    "\n",
    "#### 웹카메라 입력을 동영상으로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = 30\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')  # *'DIVX' == 'D','I','V','X'\n",
    "delay = round(1000 / fps)\n",
    "\n",
    "out = cv2.VideoWriter('./data/output.avi', fourcc, fps, (w, h))\n",
    "\n",
    "if not out.isOpened():\n",
    "    print('File open failed!')\n",
    "    cap.release()\n",
    "    sys.exit()\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    edge = cv2.Canny(frame, 50, 150)\n",
    "    edge_color = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # out.write(frame)\n",
    "    out.write(edge_color)\n",
    "\n",
    "    # cv2.imshow('frame', frame)\n",
    "    cv2.imshow('edge', edge)\n",
    "\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 키보드 이벤트 처리하기\n",
    "\n",
    "### 키보드 입력 대기 함수\n",
    "```py\n",
    "cv2.waitKey(delay=None) -> retval\n",
    "```\n",
    "- delay: 밀리초 단위 대기 시간. delay  0 이면 무한히 기다림. 기본값은 0.\n",
    "- retval: 눌린 키 값(ASCII code). 키가 눌리지 않으면 -1.\n",
    "- 참고 사항\n",
    "    - cv2.waitKey() 함수는 OpenCV 창이 하나라도 있을 때 동작함\n",
    "    - 특정 키 입력을 확인하려면 ord() 함수를 이용\n",
    "    ```py\n",
    "    while True:\n",
    "        if cv2.waitKey() == ord('q'):\n",
    "            break\n",
    "    ```\n",
    "    - 주요 특수키 코드: 27(ESC), 13(ENTER), 9(TAB)\n",
    "\n",
    "### 키보드 특수키 입력 처리하기\n",
    "- Windows 운영체제에서 방향키, 함수키 등의 특수키 입력은 **cv2.waitKeyEx()** 함수 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 키보드에서 'i' 또는 'I' 키를 누르면 영상을 반전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./data/images/cat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while 1:\n",
    "    keycode = cv2.waitKey()\n",
    "\n",
    "    if keycode == 27:\n",
    "        break\n",
    "    elif keycode == ord('i') or keycode == ord('I'):\n",
    "        img = ~img\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. 마우스 이벤트 처리하기\n",
    "\n",
    "### 마우스 이벤트 콜백함수 등록 함수\n",
    "```py\n",
    "cv2.setMouseCallback(windowName, onMouse, param=None) -> None\n",
    "```\n",
    "- windowName: 마우스 이벤트 처리를 수행할 창 이름\n",
    "- onMouse: 마우스 이벤트 처리를 위한 콜백 함수 이름. 마우스 이벤트 콜백 함수는 다음 형식을 따라야 함.\n",
    "\n",
    "    ```py\n",
    "    onMouse(event, x, y, flags, param) -> None\n",
    "    ```\n",
    "- param: 콜백 함수에 전달할 데이터\n",
    "\n",
    "### 마우스 이벤트 처리 함수(콜백 함수) 형식\n",
    "```py\n",
    "onMouse(event, x, y, flags, param) -> None\n",
    "```\n",
    "- event: 마우스 이벤트 종류. cv2.EVENT_로 시작하는 상수.\n",
    "- x: 마우스 이벤트가 발생한 x 좌표\n",
    "- y: 마우스 이벤트가 발생한 y 좌표\n",
    "- flags: 마우스 이벤트 발생 시 상태. cv2.EVENT_FLAG_로 시작하는 상수\n",
    "- param: cv2.setMouseCallback() 함수에서 설정한 데이터.\n",
    "\n",
    "### 마우스 이벤트 처리 함수의 event 인자\n",
    "| MouseEventTypes 열거형 상수 | 값 | 설명 |\n",
    "| ----- | --- | ---|\n",
    "|cv2.EVENT_MOUSEMOVE|0|마우스가 창 위에서 움직이는 경우|\n",
    "|cv2.EVENT_LBUTTONDOWN|1|마우스 왼쪽 버튼이 눌려지는 경우|\n",
    "|cv2.EVENT_RBUTTONDOWN|2|마우스 오른쪽 버튼이 눌려지는 경우|\n",
    "|cv2.EVENT_MBUTTONDOWN|3|마우스 가운데 버튼이 눌려지는 경우|\n",
    "|cv2.EVENT_LBUTTONUP|4|마우스 왼쪽 버튼이 떼어지는 경우|\n",
    "|cv2.EVENT_RBUTTONUP|5|마우스 오른쪽 버튼이 떼어지는 경우|\n",
    "|cv2.EVENT_MBUTTONUP|6|마우스 가운데 버튼이 떼어지는 경우|\n",
    "|cv2.EVENT_LBUTTONDBLCLK|7|마우스 왼쪽 버튼을 더블클릭하는 경우|\n",
    "|cv2.EVENT_RBUTTONDBLCLK|8|마우스 오른쪽 버튼을 더블클릭하는 경우|\n",
    "|cv2.EVENT_MBUTTONDBLCLK|9|마우스 가운데 버튼을 더블클릭하는 경우|\n",
    "|cv2.EVENT_MOUSEWHEEL|10|마우스 휠을 앞뒤로 돌리는 경우|\n",
    "|cv2.EVENT_MOUSEHWHEEL|11|마우스 휠을 좌우로 움직이는 경우|\n",
    "\n",
    "### 마우스 이벤트 처리 함수의 flags 인자\n",
    "- 값에 해당하는 비트가 세팅이 되어 있는지를 확인하기 위해 주로 논리 연산자를 사용\n",
    "\n",
    "| MouseEventFlags열거형 상수 | 값 | 설명 |\n",
    "| ----- | --- | ---|\n",
    "|cv2.EVENT_FLAG_LBUTTON|1|마우스 왼쪽 버튼이 눌려져 있음|\n",
    "|cv2.EVENT_FLAG_RBUTTON|2|마우스 오른쪽 버튼이 눌려져 있음|\n",
    "|cv2.EVENT_FLAG_MBUTTON|4|마우스 가운데 버튼이 눌려져 있음|\n",
    "|cv2.EVENT_FLAG_CTRLKEY|8|CTRL 키가 눌려져 있음|\n",
    "|cv2.EVENT_FLAG_SHIFTKEY|16|SHIFT 키가 눌려져 있음|\n",
    "|cv2.EVENT_FLAG_ALTKEY|32|ALT 키가 눌려져 있음|\n",
    "\n",
    "### 마우스를 이용한 그리기 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "oldx = oldy = -1\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global img, oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "        print(f'EVENT_LBUTTONDOWN: {x}, {y}')\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        print(f'EVENT_LBUTTONUP: {x}, {y}')\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            # cv2.circle(img, (x, y), 5, (0, 0, 255), -1)\n",
    "            cv2.line(img, (oldx, oldy), (x, y), (0, 0, 255), 4, cv2.LINE_AA)\n",
    "            cv2.imshow('img', img)\n",
    "            oldx, oldy = x, y\n",
    "\n",
    "img = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.setMouseCallback('img', on_mouse)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 트랙바 사용하기\n",
    "\n",
    "### 트랙바(Trackbar)란?\n",
    "- 프로그램 동작 중 사용자가 지정한 범위 안의 값을 선택할 수 있는 컨트롤\n",
    "- OpenCV에서 제공하는 (유일한?) 그래픽 사용자 인터페이스\n",
    "\n",
    "### 트랙바 생성 함수\n",
    "```py\n",
    "cv2.createTrackbar(trackbarName, windowName, value, count, onChange) -> None\n",
    "```\n",
    "- trackbarName: 트랙바 이름\n",
    "- windowName: 트랙바를 생성할 창 이름\n",
    "- value: 트랙바 위치 초기값\n",
    "- count: 트랙바 최댓값. 최솟값은 항상 0.\n",
    "- onChange: 트랙바 위치가 변경될 때마다 호출할 콜백 함수 이름\n",
    "    - 트랙바 이벤트 콜백 함수는 다음 형식을 따름\n",
    "    \n",
    "        ```py\n",
    "        onChange(pos) -> None\n",
    "        ```\n",
    "\n",
    "### 트랙바를 이용한 그레이스케일 레벨 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def on_level_changed(pos):\n",
    "    global img\n",
    "\n",
    "    level = pos * 16\n",
    "    level = np.clip(level, 0, 255)\n",
    "    \n",
    "    img[:, :] = level\n",
    "    cv2.imshow('img', img)\n",
    "\n",
    "img = np.zeros((480, 640), np.uint8)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.createTrackbar('level', 'img', 0, 16, on_level_changed)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. 연산 시간 측정 방법\n",
    "- 컴퓨터 비전은 대용량 데이터를 다루고, 일련의 과정을 통해 최종 결과를 얻으므로 매 단계에서 연산 시간을 측정하여 관리할 필요가 있음\n",
    "- OpenCV에서는 TickMeter 클래스를 이용하여 연산 시간을 측정\n",
    "\n",
    "    ```py\n",
    "    cv2.TickMeter() -> tm\n",
    "    ```\n",
    "    - tm: cv2.TickMeter 객체\n",
    "    - tm.start(): 시간 측정 시작\n",
    "    - tm.stop(): 시간 측정 끝\n",
    "    - tm.reset(): 시간 측정 초기화\n",
    "    - tm.getTimeSec(): 측정 시간을 초 단위로 반환\n",
    "    - tm.getTimeMilli(): 측정 시간을 밀리 초 단위로 반환\n",
    "    - tm.getTimeMicro(): 측정 시간을 마이크로 초 단위로 반환\n",
    "\n",
    "### 특정 연산의 시간 측정 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./data/images/hongkong.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "tm = cv2.TickMeter()\n",
    "tm.start()\n",
    "\n",
    "edge = cv2.Canny(img, 50, 150)\n",
    "\n",
    "tm.stop()\n",
    "ms = tm.getTimeMilli()\n",
    "\n",
    "print(f'Elapsed time : {ms}ms.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 실전 코딩: 동영상 전환 이펙트\n",
    "\n",
    "### 동영상 전환 이펙트\n",
    "- 두 동영상 클립 사이에 추가되는 애니메이션 효과\n",
    "- 페이드-인(fade-in), 페이드-아웃(fade-out), 디졸브(dissolve), 밀기, 확대 등\n",
    "\n",
    "### 구현할 기능 \n",
    "- 두 개의 동영상 동시 열기\n",
    "- 첫 번째 동영상의 마지막 N개 프레임과 두 번째 동영상의 처음 N개 프레임을 합성\n",
    "- 합성된 영상을 동영상으로 저장하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 두 개의 동영상을 열어서 cap1, cap2로 지정\n",
    "cap1 = cv2.VideoCapture('./data/videos/video1.mp4')\n",
    "cap2 = cv2.VideoCapture('./data/videos/video2.mp4')\n",
    "\n",
    "if not cap1.isOpened() or not cap2.isOpened():\n",
    "    print('video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 두 동영상의 크기, FPS는 같다고 가정함\n",
    "frame_cnt1 = round(cap1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_cnt2 = round(cap2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap1.get(cv2.CAP_PROP_FPS)\n",
    "effect_frames = int(fps * 2)\n",
    "\n",
    "print('frame_cnt1:', frame_cnt1)\n",
    "print('frame_cnt2:', frame_cnt2)\n",
    "print('FPS:', fps)\n",
    "\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "w = round(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = round(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "\n",
    "# 출력 동영상 객체 생성\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (w, h))\n",
    "\n",
    "# 1번 동영상 복사\n",
    "for i in range(frame_cnt1 - effect_frames):\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "    if not ret1:\n",
    "        print('frame read error!')\n",
    "        sys.exit()\n",
    "\n",
    "    out.write(frame1)\n",
    "    print('.', end='')\n",
    "\n",
    "    cv2.imshow('frame', frame1)\n",
    "    cv2.waitKey(delay)\n",
    "\n",
    "# 1번 동영상 뒷부분과 2번 동영상 앞부분을 합성\n",
    "for i in range(effect_frames):\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        print('frame read error!')\n",
    "        sys.exit()\n",
    "\n",
    "    dx = int(w / effect_frames) * i\n",
    "\n",
    "    frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    frame[:, 0:dx, :] = frame2[:, 0:dx, :]\n",
    "    frame[:, dx:w, :] = frame1[:, dx:w, :]\n",
    "\n",
    "    # Dissolve 효과 (앞 영상이 어두워지면서 다음 영상이 나타남)\n",
    "    # alpha = i / effect_frames\n",
    "    # frame = cv2.addWeighted(frame1, 1 - alpha, frame2, alpha, 0)\n",
    "\n",
    "    out.write(frame)\n",
    "    print('.', end='')\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.waitKey(delay)\n",
    "\n",
    "# 2번 동영상을 복사\n",
    "for i in range(effect_frames, frame_cnt2):\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if not ret2:\n",
    "        print('frame read error!')\n",
    "        sys.exit()\n",
    "\n",
    "    out.write(frame2)\n",
    "    print('.', end='')\n",
    "\n",
    "    cv2.imshow('frame', frame2)\n",
    "    cv2.waitKey(delay)\n",
    "\n",
    "print('\\noutput.avi file is successfully generated!')\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
